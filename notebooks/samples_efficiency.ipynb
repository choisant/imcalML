{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6422a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import seaborn as sn\n",
    "import atlas_mpl_style as ampl\n",
    "ampl.use_atlas_style()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d953ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BH_n4_M10', 'SPH_9TeV']\n"
     ]
    }
   ],
   "source": [
    "BH_labels = [\"BH_n4_M10\"]\n",
    "BH_data_paths = [f\"/disk/atlas3/data_MC/delphes/{label}_25000events.root:Delphes\" for label in BH_labels]\n",
    "\n",
    "sph_data_paths = [\"/disk/atlas3/data_MC/delphes/PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_50000events.root:Delphes\"]\n",
    "sph_labels = [\"SPH_9TeV\"]\n",
    "\n",
    "##Defines the number of high pT objects, used to perform cut\n",
    "min_pt = 70\n",
    "max_eta = 2.4 \n",
    "\n",
    "n_BH_labels = len(BH_data_paths)\n",
    "n_sph_labels = len(sph_data_paths)\n",
    "\n",
    "N_events = 25000\n",
    "\n",
    "labels = BH_labels + sph_labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1309f",
   "metadata": {},
   "source": [
    "These are some examples of how to look at root files using uproot and awkward arrays. More info in this tutorial:\n",
    "https://hub.gke2.mybinder.org/user/jpivarski-2020--ep2020-tutorial-7h7oraqf/lab/tree/tutorial.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e08570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[269]\n",
      "[25000]\n"
     ]
    }
   ],
   "source": [
    "#Open file in with-function will close it when you exit\n",
    "def load_data(rootfile:str, branch:str, keys:list):\n",
    "    with uproot.open(rootfile) as file:\n",
    "        valid_list = [key in file.keys() for key in keys]\n",
    "        if valid_list:\n",
    "            arr = file[branch].arrays(keys, library=\"ak\", how=\"zip\")[0:N_events]\n",
    "            return arr[branch]\n",
    "        else:\n",
    "            print(keys[not(valid_list)], \" not present in data.\")\n",
    "\n",
    "def get_arrays(data_paths):\n",
    "    clusters = [load_data(path, \"Tower\", \n",
    "                            [\"Tower.ET\", \"Tower.Eta\", \"Tower.Phi\", \"Tower.Eem\", \"Tower.Ehad\", \"Tower.E\"])\n",
    "                            for path in data_paths]\n",
    "\n",
    "    jets = [load_data(path, \"Jet\", \n",
    "                            [\"Jet.PT\", \"Jet.Eta\", \"Jet.Phi\"])\n",
    "                            for path in data_paths]\n",
    "                \n",
    "    met = [load_data(path, \"MissingET\", \n",
    "                            [\"MissingET.MET\", \"MissingET.Eta\", \"MissingET.Phi\"])\n",
    "                            for path in data_paths]\n",
    "\n",
    "    electrons = [load_data(path, \"Electron\", \n",
    "                            [\"Electron.PT\", \"Electron.Eta\", \"Electron.Phi\", \"Electron.Charge\"])\n",
    "                            for path in data_paths]\n",
    "\n",
    "    muons = [load_data(path, \"Muon\", \n",
    "                            [\"Muon.PT\", \"Muon.Eta\", \"Muon.Phi\", \"Muon.Charge\"])\n",
    "                            for path in data_paths]\n",
    "\n",
    "    photons = [load_data(path, \"Photon\", \n",
    "                            [\"Photon.PT\", \"Photon.Eta\", \"Photon.Phi\"])\n",
    "                            for path in data_paths]\n",
    "\n",
    "    return clusters, jets, met, electrons, muons, photons\n",
    "\n",
    "BH_clusters, BH_jets, BH_met, BH_electrons, BH_muons, BH_photons = get_arrays(BH_data_paths)\n",
    "sph_clusters, sph_jets, sph_met, sph_electrons, sph_muons, sph_photons = get_arrays(sph_data_paths)\n",
    "\n",
    "print([len(BH_clusters[i][0]) for i in range(len(BH_clusters))])\n",
    "print([len(BH_clusters[i]) for i in range(len(BH_clusters))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a90b992",
   "metadata": {},
   "source": [
    "# Jet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf25ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting data for plotting from jets\n",
    "def jet_data (jets):\n",
    "    jets = [item[item.PT > min_pt] for item in jets]\n",
    "    jets = [item[abs(item.Eta) < max_eta] for item in jets]\n",
    "    jets = [ak.pad_none(item, 1, axis=-1) for item in jets]\n",
    "    n_jets = [np.array([len(event) for event in item.PT]) for item in jets]\n",
    "    jet1_PT = [ak.to_list(item.PT[:,0]) for item in jets]\n",
    "    jet1_eta = [ak.to_list(item.Eta[:,0]) for item in jets]\n",
    "    return jets, n_jets, jet1_PT, jet1_eta\n",
    "\n",
    "BH_jets, n_BH_jets, BH_jet1_PT, BH_jet1_eta = jet_data(BH_jets)\n",
    "sph_jets, n_sph_jets, sph_jet1_PT, sph_jet1_eta = jet_data(sph_jets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3633f2db",
   "metadata": {},
   "source": [
    "# Multiplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a542ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting data for plotting from particle data\n",
    "def multiplicity(photons, electrons, muons):\n",
    "    photons = [item[item.PT > min_pt] for item in photons]\n",
    "    photons = [item[abs(item.Eta) < max_eta] for item in photons]\n",
    "    n_photons = [[len(event) for event in item.PT] for item in photons]\n",
    "    electrons = [item[item.PT > min_pt] for item in electrons]\n",
    "    electrons = [item[abs(item.Eta) < max_eta] for item in electrons]\n",
    "    n_electrons = [[len(event) for event in item.PT] for item in electrons]\n",
    "    #separate muons by charge\n",
    "    muons = [item[item.PT > min_pt] for item in muons]\n",
    "    muons = [item[abs(item.Eta) < max_eta] for item in muons]\n",
    "    muons_neg = [item[item.Charge < 0] for item in muons]\n",
    "    muons_pos = [item[item.Charge > 0] for item in muons]\n",
    "    n_muons_neg = [np.array([len(event) for event in item.PT]) for item in muons_neg]\n",
    "    n_muons_pos = [np.array([len(event) for event in item.PT]) for item in muons_pos]\n",
    "    n_muons = [np.array([len(event) for event in item.PT]) for item in muons]\n",
    "    return n_photons, n_electrons, n_muons_neg, n_muons_pos, n_muons \n",
    "\n",
    "n_BH_photons, n_BH_electrons, n_BH_muons_neg, n_BH_muons_pos, n_BH_muons = multiplicity(BH_photons, BH_electrons, BH_muons)\n",
    "n_sph_photons, n_sph_electrons, n_sph_muons_neg, n_sph_muons_pos, n_sph_muons = multiplicity(sph_photons, sph_electrons, sph_muons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c72d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#muon multiplicity\n",
    "\n",
    "def make_data(counts, labels, n_models, n_counts):\n",
    "    data = [[0]*n_counts]*n_models\n",
    "    for i in range(0, n_models):\n",
    "        data[i] = [labels[i]] + list(counts[i])\n",
    "        \n",
    "        while(len(data[i]) <= n_counts):\n",
    "            data[i] = data[i] + [0]\n",
    "        sum_muons = np.sum([data[i][k]*(k-1) for k in range(1, n_counts)])\n",
    "        data[i] = data[i] + [sum_muons]\n",
    "    return data\n",
    "\n",
    "def make_table(n_muons, labels, n_labels, type):\n",
    "    count_mu = [np.unique(item, return_counts=True)[1] for item in n_muons]\n",
    "\n",
    "    col_names = [\"Model\", \"0\", \"1\", \"2\", \"3\", \"4\", f'Total {type}']\n",
    "    n_counts = 5 #can be dynamically coded, but should not be more than 4 muons\n",
    "    \n",
    "    data_mu = make_data(count_mu, labels, n_labels, n_counts)\n",
    "    df = pd.DataFrame(data_mu, columns=col_names)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec39cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ST = scalar sum of all jets, leptons, photons and MET\n",
    "def calculate_ST(n_labels, jets, muons, electrons, photons, met):\n",
    "    ST = np.zeros((n_labels, N_events))\n",
    "    for i in range(n_labels):\n",
    "        jet_sum = np.sum(jets[i].PT, axis=-1)/1000\n",
    "        muon_sum = np.sum(muons[i].PT, axis=-1)/1000\n",
    "        electron_sum = np.sum(electrons[i].PT, axis=-1)/1000\n",
    "        photon_sum = np.sum(photons[i].PT, axis=-1)/1000\n",
    "        met_sum = np.sum(met[i].MET, axis=-1)/1000\n",
    "        k = 20\n",
    "        ST[i] = jet_sum + muon_sum + electron_sum + photon_sum + met_sum\n",
    "    return ST\n",
    "BH_ST = calculate_ST(n_BH_labels, BH_jets, BH_muons, BH_electrons, BH_photons, BH_met)\n",
    "sph_ST = calculate_ST(n_sph_labels, sph_jets, sph_muons, sph_electrons, sph_photons, sph_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311b7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuts\n",
    "BH_N = np.array(n_BH_jets) + np.array(n_BH_electrons) + np.array(n_BH_muons) + np.array(n_BH_photons)\n",
    "sph_N = np.array(n_sph_jets) + np.array(n_sph_electrons) + np.array(n_sph_muons) + np.array(n_sph_photons)\n",
    "\n",
    "#Dictionary \n",
    "df_dict = {}\n",
    "for i, label in enumerate(BH_labels):\n",
    "    df_dict[label] = pd.DataFrame({\"N\":BH_N[i], \"ST\":BH_ST[i]})\n",
    "\n",
    "for i, label in enumerate(sph_labels):\n",
    "    df_dict[label] = pd.DataFrame({\"N\":sph_N[i], \"ST\":sph_ST[i]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac77884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency for N >= 5 and ST >= 6:\n",
      "BH_n4_M10: 0.62\n",
      "SPH_9TeV: 0.56\n",
      "Efficiency for N >= 5 and ST >= 7:\n",
      "BH_n4_M10: 0.49\n",
      "SPH_9TeV: 0.18\n",
      "Efficiency for N >= 6 and ST >= 6:\n",
      "BH_n4_M10: 0.41\n",
      "SPH_9TeV: 0.53\n",
      "Efficiency for N >= 6 and ST >= 7:\n",
      "BH_n4_M10: 0.32\n",
      "SPH_9TeV: 0.17\n",
      "Efficiency for N >= 7 and ST >= 6:\n",
      "BH_n4_M10: 0.22\n",
      "SPH_9TeV: 0.45\n",
      "Efficiency for N >= 7 and ST >= 7:\n",
      "BH_n4_M10: 0.17\n",
      "SPH_9TeV: 0.15\n"
     ]
    }
   ],
   "source": [
    "def efficiency(dictionary, N_cut, ST_cut, labels):\n",
    "    print(f\"Efficiency for N >= {N_cut} and ST >= {ST_cut}:\")\n",
    "    file.write(f\"Efficiency for N >= {N_cut} and ST >= {ST_cut}:\\n\")\n",
    "    for label in labels:\n",
    "        df = dictionary[label]\n",
    "        N_before = len(df)\n",
    "        df = df[df[\"N\"] >= N_cut]\n",
    "        df = df[df[\"ST\"] >= ST_cut] \n",
    "        N_after = len(df)\n",
    "        print(f\"{label}: {np.round(N_after/N_before, 2)}\")\n",
    "        file.write(f\"{label}: {np.round(N_after/N_before, 2)}\\n\")\n",
    "\n",
    "N_cuts = [5, 6, 7]\n",
    "ST_cuts = [6, 7]\n",
    "\n",
    "file = open(\"../results/Efficiencies.txt\", \"w\")\n",
    "\n",
    "for N_cut in N_cuts:\n",
    "    for ST_cut in ST_cuts:\n",
    "        efficiency(df_dict, N_cut, ST_cut, labels)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('matrices': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b1332e5a07ce33895000dbe941ad9cee852d3baee8993fa123c6057492c40e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
